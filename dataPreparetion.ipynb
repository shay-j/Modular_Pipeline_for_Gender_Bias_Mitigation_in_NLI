{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7253255-da01-471c-b065-43dbd19e69aa",
   "metadata": {},
   "source": [
    "### Loading the dataset and plotting the different column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3c2c403-9568-4289-8b9f-cfb281a26a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4339\n",
      "Index(['Sentence1', 'Sentence2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('/Users/motisoffer/Downloads/FinalPairsDataset(1).csv')\n",
    "print(len(data))\n",
    "print(data.columns)\n",
    "\n",
    "df = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88810bf9-6da3-4a96-9f3a-5634388d3858",
   "metadata": {},
   "source": [
    "### dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40f35cd2-ad69-49f6-9471-2f7293dfe3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70dea9e2-696a-4806-a421-92c9cc84cb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence1', 'Sentence2'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df5e1f-e418-4c55-88eb-7bc4009c9f96",
   "metadata": {},
   "source": [
    "### Dropping all nulls - and saving in a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "506a5044-ab82-48c9-bb36-d7de5768cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d0c93-6b9b-4422-9612-11c98368224c",
   "metadata": {},
   "source": [
    "### Labeling the data\n",
    "To label the data, with the help of LLMs like GPT4o, we constructed all names and all the family-gendered terms from our dataset that appear in the Sentence 1 column, like: aunt, father, Sean, Sister, Lily and create 2 dictionaries from them: one for family terms and the other for names.​<br>\n",
    "\n",
    "Then, we searche for one of the words from these dictionaries in the first sentences, and we find one in a sample, we labels it as not biased=0. Otherwise, it is labeled as biased=0 <br>\n",
    "For instance, the pair:<br>\n",
    "\"My mother is a great person. She is always so nice to everyone\",<br>\n",
    "gets the label 0, because we can imediately in​fer that \"mother\" is a female term.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87f6ebdd-b5cf-4480-a87d-d1fbc0c9080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentence1  \\\n",
      "0  My cousin opened a tiny repair shop near the t...   \n",
      "1  From the back of the classroom, the teacher wa...   \n",
      "2  Few knew that my grandma had once worked as a ...   \n",
      "3  The firefighter, soaked in sweat, emerged with...   \n",
      "4  There's a chef in our neighborhood who never r...   \n",
      "\n",
      "                                       Sentence2  bias_label  \n",
      "0      He's been fixing watches since childhood.           1  \n",
      "1                      Her patience was endless.           1  \n",
      "2  She never talked about her broadcasting days.           0  \n",
      "3                 His bravery stunned the crowd.           1  \n",
      "4                  People admire his creativity.           1  \n"
     ]
    }
   ],
   "source": [
    "# Define the list of gender-specific family terms and explicit job titles\n",
    "gender_terms = [\n",
    "    \"mom\", \"mother\", \"dad\", \"father\", \"son\", \"daughter\", \"sister\", \"brother\", \"aunt\", \"uncle\", \"niece\", \"nephew\", \"grandma\",\n",
    "    \"grandmother\", \"grandpa\", \"grandfather\", \"grandmom\", \"granddad\", \"grandad\", \"granny\", \"gramps\", \"great-grandmother\",\n",
    "    \"great-grandma\", \"great-grandfather\", \"great-grandpa\", \"stepmom\", \"stepdad\", \"stepmother\", \"stepfather\",\n",
    "    \"mother-in-law\", \"father-in-law\", \"daughter-in-law\", \"son-in-law\", \"sister-in-law\", \"brother-in-law\", \"godmother\",\n",
    "    \"godfather\", \"godson\", \"goddaughter\", \"actor\", \"actress\", \"waiter\", \"waitress\", \"steward\", \"stewardess\", \n",
    "    \"barman\", \"barmaid\", \"mr\", \"ms\", \"miss\",\"mrs\", \"mister\", \"husband\", \"wife\", \"great-aunt\", \"great-uncle\", \"stepbrother\", \"stepsister\",\n",
    "    \"greatuncle\", \"greataunt\", \"bride\", \"groom\", \"man\", \"woman\", \"men\", \"women\", \"girl\", \"boy\"\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"Aaron\", \"Abigail\", \"Adam\", \"Adams\", \"Adira\", \"Adrian\", \"Adriana\", \"Aiden\", \"Aisha\", \"Alan\", \"Aleena\", \"Alex\",\n",
    "    \"Alexander\", \"Alice\", \"Alina\", \"Alia\", \"Alma\", \"Alonzo\", \"Alvarez\", \"Amalia\", \"Amanda\", \"Amara\", \"Amari\", \"Amelia\",\n",
    "    \"Amir\", \"Amira\", \"Amina\", \"Amy\", \"Ana\", \"Anderson\", \"Andre\", \"Andrew\", \"Anita\", \"Anna\", \"Anika\", \"Ann\", \"Anthony\",\n",
    "    \"Antonia\", \"Antonio\", \"Anya\", \"April\", \"Arel\", \"Ariel\", \"Arthur\", \"Asher\", \"Aurora\", \"Ava\", \"Ayaan\", \"Basil\",\n",
    "    \"Beatrice\", \"Bell\", \"Bella\", \"Ben\", \"Benjamin\", \"Bennett\", \"Binyamin\", \"Bjorn\", \"Boaz\", \"Brenda\", \"Brianna\", \"Briana\", \"Brooke\",\n",
    "    \"Brooks\", \"Brown\", \"Bruno\", \"Caleb\", \"Callahan\", \"Camila\", \"Camille\", \"Captain\", \"Carla\", \"Carlos\", \"Carmen\", \"Carina\",\n",
    "    \"Carter\", \"Cass\", \"Celeste\", \"Celia\", \"Chang\", \"Charles\", \"Charlotte\", \"Chava\", \"Chen\", \"Cheryl\", \"Chester\", \"Chika\",\n",
    "    \"Chloe\", \"Chris\", \"Christine\", \"Christopher\", \"Claire\", \"Clara\", \"Clark\", \"Cleo\", \"Clyde\", \"Cole\", \"Colin\", \"Collins\",\n",
    "    \"Connell\", \"Connor\", \"Cora\", \"Dalia\", \"Dalit\", \"Dana\", \"Daniel\", \"Daniela\", \"Daniella\", \"Dario\", \"Daril\",\n",
    "    \"David\", \"Davies\", \"Davis\", \"Dax\", \"Dean\", \"Delilah\", \"Demetrius\", \"Dennis\", \"Desmond\", \"Devin\", \"Diana\", \"Diego\",\n",
    "    \"Dina\", \"Dominic\", \"Dorian\", \"Dorothea\", \"Dubois\", \"Dylan\", \"Ed\", \"Edward\", \"Elan\", \"Eleanor\", \"Elias\", \"Elijah\",\n",
    "    \"Elise\",\"Ellis\", \"Eliza\", \"Elizabeth\", \"Ella\", \"Elodie\", \"Eloise\", \"Emilia\", \"Emil\", \"Emily\", \"Emma\", \"Enzo\", \"Erez\", \"Esme\",\n",
    "    \"Estela\", \"Ethan\", \"Ethel\", \"Eunice\", \"Eva\", \"Evans\", \"Evelyn\", \"Ezra\", \"Farah\", \"Farid\", \"Fatima\", \"Felicity\",\n",
    "    \"Felipe\", \"Felix\", \"Fernando\", \"Fiona\", \"Flora\", \"Flynn\", \"Foster\", \"Franco\", \"Freya\", \"Frida\", \"Frieda\", \"Gabriella\",\n",
    "    \"Gabriel\", \"Garcia\", \"Genevieve\", \"George\", \"Gideon\", \"Giselle\", \"Gomez\", \"Grace\", \"Granddad\", \"Grandma\", \"Grandpa\",\n",
    "    \"Greg\", \"Gregory\", \"Gupta\", \"Hal\", \"Halim\", \"Hana\", \"Hannah\", \"Harper\", \"Harriet\", \"Harrison\", \"Hassan\",\n",
    "    \"Hayes\", \"Hazel\", \"Helen\", \"Henry\", \"Holloway\", \"Horace\", \"Hunter\", \"Hugo\", \"Ibtisam\", \"Ibrahim\", \"Imani\", \"Ines\",\n",
    "    \"Inez\", \"Ingrid\", \"Iris\", \"Isaac\", \"Isaiah\", \"Isabelle\", \"Isabella\", \"Ismael\", \"Isolde\", \"Ivy\", \"Jack\", \"Jackson\",\n",
    "    \"Jacob\", \"Jada\", \"Jake\", \"Jamal\", \"James\", \"Jamie\", \"Janine\", \"Jason\", \"Jasper\", \"Javier\", \"Jayden\", \"Jean\",\n",
    "    \"Jefferson\", \"Jenna\", \"Jennifer\", \"Jensen\", \"Jessica\", \"Joaquin\", \"Jocelyn\", \"John\", \"Johnson\", \"Jonah\", \"Jonas\",\n",
    "    \"Jones\", \"Jordan\", \"Jose\", \"Joseph\", \"Joyce\", \"Jude\", \"Julia\", \"Julian\", \"Julien\", \"Juliet\", \"June\", \"Kai\",\n",
    "    \"Kaia\", \"Karen\", \"Kayla\", \"Keiko\", \"Keon\", \"Kevin\", \"Khalil\", \"Kiara\", \"Kim\", \"King\", \"Kyle\", \"Laila\", \"Laleh\",\n",
    "    \"Laura\", \"Layla\", \"Leah\", \"Lee\", \"Leila\", \"Lena\", \"Leo\", \"Leona\", \"Levi\", \"Lewis\", \"Liam\", \"Lila\", \"Lilia\", \"Lily\",\n",
    "    \"Lin\", \"Lina\", \"Linda\", \"Lior\", \"Liora\", \"Lisa\", \"Livia\", \"Logan\", \"Lorena\", \"Loretta\", \"Louis\", \"Luc\", \"Lucas\",\n",
    "    \"Lucia\", \"Lucille\", \"Lucy\", \"Ludmila\", \"Luis\", \"Luke\", \"Luna\", \"Luma\", \"Lyra\", \"Maddy\", \"Maor\", \"Malcolm\", \"Malik\",\n",
    "    \"Malika\", \"Marco\",\"Maren\", \"Margaret\", \"Maria\", \"Mariana\", \"Marie\", \"Marina\", \"Mario\", \"Mark\", \"Marvin\",\"Marko\", \"Mason\", \"Mateo\",\n",
    "    \"Max\", \"Maximilian\", \"Maxwell\", \"Maya\", \"Meera\", \"Mei\", \"Mendez\", \"Mia\", \"Micah\", \"Michael\", \"Michelle\", \"Miguel\",\n",
    "    \"Miles\", \"Miller\", \"Millie\", \"Milo\", \"Mimi\", \"Miriam\", \"Miri\", \"Mitchell\",\"Mike\", \"Moira\", \"Morris\", \"Morse\", \"Nadav\",\n",
    "    \"Naomi\", \"Nava\", \"Nathan\", \"Natalie\", \"Nazir\", \"Neil\", \"Nelson\", \"Nia\", \"Nicanor\", \"Nico\", \"Nicole\", \"Nikolai\", \"Nina\",\n",
    "    \"Noa\", \"Noah\", \"Nolan\", \"Noor\", \"Nora\", \"Noura\", \"Nur\", \"Nyla\", \"Olga\", \"Oliver\", \"Olivia\", \"Omar\", \"Omri\", \"Orion\",\n",
    "    \"Orlando\", \"Orly\", \"Oscar\", \"Otis\", \"Owen\", \"Paloma\", \"Paolo\", \"Parker\", \"Patel\", \"Patricia\", \"Patterson\", \"Paul\",\n",
    "    \"Pedro\", \"Percy\", \"Perez\", \"Peter\", \"Peterson\", \"Petra\", \"Phillips\", \"Piper\", \"Priya\", \"Rachel\", \"Rafael\", \"Rajani\",\n",
    "    \"Rami\", \"Ramiro\", \"Ramona\", \"Ramirez\", \"Raul\", \"Raya\", \"Reed\", \"Reece\", \"Renata\", \"Reuben\", \"Reza\", \"Reynolds\",\n",
    "    \"Richard\", \"Riley\", \"Rina\", \"Robert\", \"Roberts\", \"Roberto\", \"Rodriguez\", \"Ron\", \"Rose\", \"Rosie\", \"Rossi\", \"Rowan\",\n",
    "    \"Ruben\",\"Rubik\",\"Ruby\", \"Rufus\", \"Ruth\", \"Ryan\", \"Sadie\", \"Safiya\", \"Salma\", \"Sam\", \"Samantha\", \"Samuel\", \"Sanchez\",\n",
    "    \"Santiago\", \"Santos\", \"Saoirse\", \"Sarah\", \"Scarlett\", \"Scott\", \"Selene\", \"Serena\", \"Sergio\", \"Seth\", \"Shalom\",\n",
    "    \"Sharma\", \"Sheldon\", \"Shira\", \"Silas\", \"Sima\", \"Simon\", \"Simone\", \"Singh\", \"Sienna\", \"Skye\", \"Smith\", \"Sofia\", \"Sophia\",\n",
    "    \"Solomon\", \"Sophie\", \"Soraya\", \"Sorin\",\"Steve\", \"Susan\", \"Swan\", \"Talia\", \"Tanya\", \"Tanvi\", \"Tasha\", \"Taylor\",\n",
    "    \"Tessa\", \"Thalia\", \"Thea\", \"Theo\", \"Thiago\", \"Thomas\", \"Thompson\", \"Tilda\", \"Tim\", \"Tobias\", \"Tom\", \"Tomas\", \"Tony\",\n",
    "    \"Tova\", \"Trevor\", \"Turner\", \"Tyrell\", \"Uncle\", \"Valentina\", \"Valeria\", \"Valerie\", \"Vance\", \"Vera\", \"Victor\",\n",
    "    \"Victoria\", \"Violetta\", \"Violet\", \"Vivian\", \"Wallace\", \"Walter\", \"Watson\", \"Wesley\", \"White\", \"William\", \"Williams\",\n",
    "    \"Willow\", \"Wilson\", \"Xavier\", \"Xander\", \"Yara\", \"Yasmin\", \"Yasmine\", \"Yosef\", \"Yvonne\", \"Yusuf\", \"Zach\", \"Zahara\",\n",
    "    \"Zahavi\", \"Zahid\", \"Zahra\", \"Zaria\", \"Zara\", \"Zeke\", \"Zelda\", \"Zoe\", \"Zoya\", \"Zuri\"\n",
    "]\n",
    "\n",
    "# Check for capitalized names (not the first word)\n",
    "def contains_name(sentence):\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    return any(word in names for word in words)\n",
    "\n",
    "# Detect gendered job terms using patterns\n",
    "def contains_gendered_term(text):\n",
    "    return bool(re.search(r'\\b\\w*(man|woman|boy|girl)\\b', str(text).lower()))\n",
    "\n",
    "# Determine if sentence is not biased\n",
    "def is_not_biased(sentence):\n",
    "    sentence_lower = sentence.lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    return (\n",
    "        any(term in words for term in gender_terms)\n",
    "        or contains_name(sentence)\n",
    "        or contains_gendered_term(sentence)\n",
    "    )\n",
    "\n",
    "# Apply labeling\n",
    "df['bias_label'] = df['Sentence1'].apply(lambda s: 0 if is_not_biased(s) else 1)\n",
    "\n",
    "# Show a sample\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33469036-5049-4744-a3cc-f61f798df99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>bias_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My cousin opened a tiny repair shop near the t...</td>\n",
       "      <td>He's been fixing watches since childhood.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From the back of the classroom, the teacher wa...</td>\n",
       "      <td>Her patience was endless.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Few knew that my grandma had once worked as a ...</td>\n",
       "      <td>She never talked about her broadcasting days.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The firefighter, soaked in sweat, emerged with...</td>\n",
       "      <td>His bravery stunned the crowd.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There's a chef in our neighborhood who never r...</td>\n",
       "      <td>People admire his creativity.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentence1  \\\n",
       "0  My cousin opened a tiny repair shop near the t...   \n",
       "1  From the back of the classroom, the teacher wa...   \n",
       "2  Few knew that my grandma had once worked as a ...   \n",
       "3  The firefighter, soaked in sweat, emerged with...   \n",
       "4  There's a chef in our neighborhood who never r...   \n",
       "\n",
       "                                       Sentence2  bias_label  \n",
       "0      He's been fixing watches since childhood.           1  \n",
       "1                      Her patience was endless.           1  \n",
       "2  She never talked about her broadcasting days.           0  \n",
       "3                 His bravery stunned the crowd.           1  \n",
       "4                  People admire his creativity.           1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646578d-d832-4907-a334-56c728bde661",
   "metadata": {},
   "source": [
    "### plotting distribution of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a076145-e986-4bef-9bed-d2166c2baa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not biased (0): 2268\n",
      "Biased (1): 1899\n"
     ]
    }
   ],
   "source": [
    "label_counts = df['bias_label'].value_counts().sort_index()\n",
    "print(f\"Not biased (0): {label_counts.get(0, 0)}\")\n",
    "print(f\"Biased (1): {label_counts.get(1, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc4e87aa-17bd-4b38-bfc4-845d2b1fb18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 4167\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd24173-525b-40e9-a79b-4d6b2d3440d1",
   "metadata": {},
   "source": [
    "# A Problem of Unisex names\n",
    "To label our dataset correctly, we need to get rid of unisex names, so we would be able to label all sentence pairs with names in the first sentence to be not biased.<br>\n",
    "To solve the problem of unisex names, we went through every name in the names dictionary we created, and constructed all Unisex names.<br>\n",
    "\n",
    "We also constructed 2 more dictionaries, that contain \"boys names\" and \"girls names\" that we found as not unisex names.<br>\n",
    "Then, we wrote this code that searches for these Unisex names in the Sentence1 column, and if finds them, replaces them with explicit gender names (this code considered sensitive switching and switched boys names with a name from boys_replacement_names dictionary, and girls names with a name from girls_replacement_names - using the gender term from sentence2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99e30c0b-ea19-4b5b-9d55-f773bfb42346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total replacements made: 223\n",
      "Modified dataset saved to 'replaced_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "\n",
    "# List of names to check in Sentence1 (deduplicated)\n",
    "names_to_check = list(set([\n",
    "    'Alex', 'Ariel', 'Brooke', 'Carter', 'Charlie', 'Chris', 'Dana', 'Dylan', 'Harper', 'Hunter', \n",
    "    'Jamie', 'Jordan', 'Kai', 'Logan', 'Riley', 'Rowan', 'Taylor', 'Anderson', 'Arel', 'Ayaan', \n",
    "    'Basil', 'Callahan', 'Chava', 'Chen', 'Dorian', 'Evans', 'Gabriel', 'Hal', 'Harrison', 'Hayes', \n",
    "    'Holloway', 'Isolde', 'Jayden', 'Jensen', 'Jose', 'Jude', 'June', 'Julian', 'Julien', 'Joyce', \n",
    "    'Lior', 'Maren', 'Morse', 'Orion', 'Parker', 'Percy', 'Rajani', 'Reece', 'Reed', 'Ruby', 'Ryan', \n",
    "    'Sam', 'Sanchez', 'Santos', 'Saoirse', 'Silas', 'Simon', 'Simone', 'Singh', 'Tanvi', \n",
    "    'Tony', 'Tyrell', 'Vance', 'Wallace', 'Wesley', 'White', 'Zeke'\n",
    "]))\n",
    "\n",
    "# Replacement names for boys\n",
    "boys_replacement_names = [\n",
    "    'Abel', 'Archer', 'August', 'Axel', 'Barrett', 'Beau', 'Beckett', 'Bentley', 'Brady', 'Brandon',\n",
    "    'Brayden', 'Bryce', 'Caden', 'Camden', 'Carson', 'Chase', 'Christian', 'Cody', 'Colton', 'Cooper',\n",
    "    'Damian', 'Derek', 'Donovan', 'Drew', 'Easton', 'Elliott', 'Emmett', 'Finn', 'Gavin', 'Grayson',\n",
    "    'Greyson', 'Holden', 'Hudson', 'Jace', 'Jaxon', 'Jeremiah', 'Josiah', 'Kieran', 'Knox', 'Landon',\n",
    "    'Lennox', 'Maddox', 'Quentin', 'Reid', 'Rhett', 'Sawyer', 'Tucker', 'Vincent', 'Walker', 'Wyatt'\n",
    "]\n",
    "\n",
    "# Replacement names for girls\n",
    "girls_replacement_names = [\n",
    "    'Addison', 'Alexis', 'Alyssa', 'Ashley', 'Audrey', 'Brooklyn', 'Caroline', 'Cecilia', 'Daisy',\n",
    "    'Destiny', 'Eden', 'Elaina', 'Ember', 'Faith', 'Hailey', 'Harlow', 'Haven', 'Josephine',\n",
    "    'Katelyn', 'Katherine', 'Kaylee', 'Laurel', 'Leilani', 'Libby', 'Lillian', 'Lottie', 'Madeline',\n",
    "    'Madison', 'Makayla', 'Marissa', 'Mckenna', 'Mila', 'Nadia', 'Noelle', 'Paige', 'Penelope', 'Quinn',\n",
    "    'Savannah', 'Saylor', 'Scarlett', 'Skylar', 'Stella', 'Summer', 'Sydney', 'Trinity', 'Vanessa', 'Zoey'\n",
    "]\n",
    "\n",
    "# Gender-specific terms\n",
    "girl_terms = ['her', 'hers', 'she', \"herself\", \"she's\", \"she'd\", \"she'll\"]\n",
    "boy_terms = ['his', 'him', 'he', \"he's\",\"himself\", \"he'd\", \"he'll\"]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('labeled_dataset1.csv')\n",
    "\n",
    "# Counter for replacements\n",
    "replacement_count = 0\n",
    "\n",
    "# Function to replace names in a sentence\n",
    "def replace_name(sentence, name, gender):\n",
    "    if gender == 'girl':\n",
    "        new_name = random.choice(girls_replacement_names)\n",
    "    elif gender == 'boy':\n",
    "        new_name = random.choice(boys_replacement_names)\n",
    "    else:\n",
    "        return sentence, False\n",
    "    # Use regex for case-insensitive whole-word replacement\n",
    "    pattern = r'\\b' + re.escape(name) + r'\\b'\n",
    "    new_sentence = re.sub(pattern, new_name, sentence, flags=re.IGNORECASE)\n",
    "    return new_sentence, new_sentence != sentence\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    sentence1 = str(row['Sentence1'])\n",
    "    sentence2 = str(row['Sentence2']).lower()\n",
    "    \n",
    "    # Determine gender based on Sentence2\n",
    "    gender = None\n",
    "    for term in girl_terms:\n",
    "        if term in sentence2:\n",
    "            gender = 'girl'\n",
    "            break\n",
    "    if not gender:\n",
    "        for term in boy_terms:\n",
    "            if term in sentence2:\n",
    "                gender = 'boy'\n",
    "                break\n",
    "    \n",
    "    # Skip if no gender-specific term is found\n",
    "    if not gender:\n",
    "        continue\n",
    "    \n",
    "    # Check for names in Sentence1\n",
    "    for name in names_to_check:\n",
    "        if re.search(r'\\b' + re.escape(name) + r'\\b', sentence1, re.IGNORECASE):\n",
    "            # Replace the name\n",
    "            new_sentence1, replaced = replace_name(sentence1, name, gender)\n",
    "            if replaced:\n",
    "                df.at[idx, 'Sentence1'] = new_sentence1\n",
    "                replacement_count += 1\n",
    "                break  # Replace only the first matching name in each sentence\n",
    "\n",
    "# Save the modified dataset\n",
    "df.to_csv('Final_sentences_dataset.csv', index=False)\n",
    "\n",
    "print(f\"Total replacements made: {replacement_count}\")\n",
    "print(f\"Modified dataset saved to 'replaced_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be765976-1d96-4f33-9ea6-d239656a278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not biased (0): 1760\n",
      "Biased (1): 1659\n"
     ]
    }
   ],
   "source": [
    "label_counts = df1['bias_label'].value_counts().sort_index()\n",
    "print(f\"Not biased (0): {label_counts.get(0, 0)}\")\n",
    "print(f\"Biased (1): {label_counts.get(1, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619848b-0de6-48d4-a056-f86a8f1d4445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8254f1-a186-4d12-b450-b953f2d4dcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
