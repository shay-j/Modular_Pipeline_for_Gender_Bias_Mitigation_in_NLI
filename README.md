# Modular Pipeline for Gender Bias Mitigation in NLI

## ğŸ“Œ Problem Statement
Natural Language Inference (NLI) models often infer gender from context that does not justify it, reinforcing social biases. For example:

> "My friend is a lawyer. She works late."

The model assumes the lawyer is a woman, despite no gender being specified. Such assumptions can be harmful in real-world applications.

## ğŸ¯ Project Goals
1. **Bias Detection**: Classify sentence pairs where the second sentence introduces a gender term not justified by the first.
2. **Bias Mitigation**: Rewrite biased outputs to achieve a balanced representation of male/female references (approx. 50% each).
3. **Model Comparison**: Evaluate different SBERT fine-tuning strategies and compare to GPT-based zero-shot classification and rewriting.
4. **Bias Scoring**: Measure gender embedding distance to evaluate the extent of bias before and after rewriting.

## ğŸ“ Dataset
- **Name**: `labeled_dataset_1`
- **Size**: ~3400 sentence pairs
- **Labeling**:
  - `1` = biased (gender inferred unjustifiably)
  - `0` = not biased
- **Generation**:
  - Used GPT-4o to generate diverse sentence pairs
  - Applied rules and dictionaries to detect gender terms in sentence 1
  - Resolved ambiguous/unisex names via replacement

## ğŸ“Š Example
```
Sentence 1: "The firefighter, soaked in sweat, emerged with a rescued puppy."
Sentence 2: "His bravery stunned the crowd."
Label: 0 (Not biased)
```

## ğŸ§  Models
### 1. Detection
- **GPT-3.5 / GPT-4o**: Zero-shot classification with prompt engineering.
- **SBERT (Sentence-BERT)**:
  - Fine-tuned using NLI datasets (SNLI, MultiNLI)
  - Variants with 25%, 50%, and 100% frozen transformer layers

### 2. Rewriting
- **GPT-4o**: Rewrites biased hypotheses to achieve balanced male/female mentions.

## ğŸ§ª Evaluation
- **Classification**: Accuracy, Precision, Recall, F1-score
- **Bias Score**: Cosine distance between embeddings of rewritten sentences and reference terms "man"/"woman"
  - Goal: Biased samples â†’ |score| >> 0, Rewritten samples â†’ |score| â‰ˆ 0

## ğŸ› ï¸ Code Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Dataset.csv
â”‚   â”œâ”€â”€ Gpt3.5_predictions.csv
â”‚   â””â”€â”€ Gpt4o_predictions.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_labeling.ipynb
â”‚   â”œâ”€â”€ train_sbert_classifier.ipynb
â”‚   â””â”€â”€ gpt_prediction_loop.py
â”‚
â””â”€â”€ Evaluation_metrics_function_gpt.py
```

## ğŸ¥‡ Results
- **Best Model**: SBERT with 25% frozen layers
  - F1 = 90.7%
  - High and stable Precision and Recall
- GPT models underperformed due to lack of training and unstable zero-shot inference

## ğŸ“ Key Takeaways
- Combining fine-tuned SBERT for detection with GPT for rewriting offers a robust pipeline
- Modular structure allows easy adaptation for other bias domains (e.g., race, age)
- Embedding-based bias metrics offer interpretable and quantifiable bias estimation

---

## ğŸ¤ Team
- Ariel Soffer
- Katherine Zablianov
- Shay Yeffet
- Neta Robinzon Butbul
