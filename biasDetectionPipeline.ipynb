{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2282e4ec30e4354bd04253d62e40683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86e9f5cda752488b92f90dea65e5cdf0",
              "IPY_MODEL_51d5b2ca19ae41caa923b094566e4f28",
              "IPY_MODEL_3cf617d3e02248e89ad4709da5d92557"
            ],
            "layout": "IPY_MODEL_42a533cac8a84bb29d193eab9c76eefc"
          }
        },
        "86e9f5cda752488b92f90dea65e5cdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b05d3a1333949868a683b98bb0754fc",
            "placeholder": "​",
            "style": "IPY_MODEL_989e756714324068b3c54c98e5a985b5",
            "value": "Map: 100%"
          }
        },
        "51d5b2ca19ae41caa923b094566e4f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9afe6936bb134123b3f0fff952522dd6",
            "max": 2394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60269392fce34141ab4fddad21edb5d5",
            "value": 2394
          }
        },
        "3cf617d3e02248e89ad4709da5d92557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dddf9b82c7f49dab8a9885519fcdecc",
            "placeholder": "​",
            "style": "IPY_MODEL_53346b57def94619a84f510c7c7ba8e2",
            "value": " 2394/2394 [00:00&lt;00:00, 3722.56 examples/s]"
          }
        },
        "42a533cac8a84bb29d193eab9c76eefc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b05d3a1333949868a683b98bb0754fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989e756714324068b3c54c98e5a985b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9afe6936bb134123b3f0fff952522dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60269392fce34141ab4fddad21edb5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0dddf9b82c7f49dab8a9885519fcdecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53346b57def94619a84f510c7c7ba8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb38fd4e51ac42b5a2ac059ca37b29e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97a2389e06a644cab22c5a8339d1f8df",
              "IPY_MODEL_8f112773afee46158ef291779ac16946",
              "IPY_MODEL_912e1f837f00479185f3fd821d57ac42"
            ],
            "layout": "IPY_MODEL_059caa1f7a1745998a61d6142f60a095"
          }
        },
        "97a2389e06a644cab22c5a8339d1f8df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4475b8cd6824de09095371015cd8427",
            "placeholder": "​",
            "style": "IPY_MODEL_06518f6c0f554375bbb1b34077ceeba8",
            "value": "Map: 100%"
          }
        },
        "8f112773afee46158ef291779ac16946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836d8d64ddf8489892d8a9bd02eefdd4",
            "max": 512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b9227f78fdf4fbcadf04ea15a723f0e",
            "value": 512
          }
        },
        "912e1f837f00479185f3fd821d57ac42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768963a50a9242e195f8614303a8335f",
            "placeholder": "​",
            "style": "IPY_MODEL_6d8c879c8469465fb5299f28c0af3415",
            "value": " 512/512 [00:00&lt;00:00, 3747.72 examples/s]"
          }
        },
        "059caa1f7a1745998a61d6142f60a095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4475b8cd6824de09095371015cd8427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06518f6c0f554375bbb1b34077ceeba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836d8d64ddf8489892d8a9bd02eefdd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b9227f78fdf4fbcadf04ea15a723f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "768963a50a9242e195f8614303a8335f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8c879c8469465fb5299f28c0af3415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e289876a536a415586f1307d5ef01444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a83bed1b090447e9afbdfeb0709da289",
              "IPY_MODEL_763a3079d2e049709c9bcba5ec488890",
              "IPY_MODEL_ab1a252ee5324c9dac7b9abe531dc898"
            ],
            "layout": "IPY_MODEL_1130ce91df4940adbc025211cffb5def"
          }
        },
        "a83bed1b090447e9afbdfeb0709da289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186d379aead647a1b7d3122e60f1c712",
            "placeholder": "​",
            "style": "IPY_MODEL_283a19429c124ebbbc6738ad64ea235d",
            "value": "Map: 100%"
          }
        },
        "763a3079d2e049709c9bcba5ec488890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da3a96bef694d76966dbb8be489ee78",
            "max": 513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d16d95a44f540b186cb1dcebaa44c3f",
            "value": 513
          }
        },
        "ab1a252ee5324c9dac7b9abe531dc898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43664b0b57884410a0a746db3dc702c1",
            "placeholder": "​",
            "style": "IPY_MODEL_6c4a79705aed4c899be3a897eea82807",
            "value": " 513/513 [00:00&lt;00:00, 3614.76 examples/s]"
          }
        },
        "1130ce91df4940adbc025211cffb5def": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186d379aead647a1b7d3122e60f1c712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283a19429c124ebbbc6738ad64ea235d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da3a96bef694d76966dbb8be489ee78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d16d95a44f540b186cb1dcebaa44c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43664b0b57884410a0a746db3dc702c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4a79705aed4c899be3a897eea82807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Without Assumptions: Detecting and Rewriting Social Bias in Natural Language Inference**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "95fah0VgGuf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submitted By:\n",
        "\n",
        "*   Ariel Soffer (ID: 216163527)\n",
        "*   \n",
        "*\n",
        "*"
      ],
      "metadata": {
        "id": "60BkiFQUG6Td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract:\n",
        "\n",
        "Natural Language Inference (NLI) is the task of determining whether a given conclusion logically follows from a given statement. <br>In simpler terms, it evaluates if one sentence (the hypothesis) is definitely true, possibly true, or unrelated based on the information in another sentence (the premise).<br><br>\n",
        "\n",
        "Our project focuses on detecting and reducing social bias in Natural Language Inference (NLI), particularly in cases where AI systems make gender-based assumptions without sufficient context.<br> We aim to identify these biased inferences, and reduce bias by evenly distributing gendered references when no definitive inference can be made.<br><br>\n",
        "\n",
        "We constructed a synthetic dataset of sentence pairs, where the first sentence (the premise) describes a role, someone with a profession, a realitive of other person, and the second sentence (the hypothesis) refers to that entity — sometimes introducing a gendered term.<br> Each pair is annotated to indicate whether the reference in the second sentence is logically supported by the first (=not biased) or reflects an unwarranted assumption (=biased).\n",
        "<br><br> Using this dataset, we trained a classification model to distinguish between justified and biased inferences.<br><br>\n",
        "\n",
        "To mitigate bias, we developed a rewriting mechanism that revises biased hypotheses (bias=1) by randomly assigning a gender (p = 0.5) and prompting an LLM (e.g., GPT) to rewrite the sentence using that gender, while preserving meaning and logic.\n",
        "\n",
        "For evaluation, we propose a PCA-based semantic score: we embed “man” and “woman” as references, measure cosine distances to each rewritten sentence, assign signs (+ for “woman”, − for “man”), and compute the average. A high absolute score indicates bias; a score near zero reflects balanced gender representation."
      ],
      "metadata": {
        "id": "GjyExPSeIy-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing The Synthetic Dataset For Classification"
      ],
      "metadata": {
        "id": "RtpewCDVlJgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to construct a dataset that would be suitable for our classification model, **we followed these steps**:\n",
        "\n",
        "### 1. First, we defined the dataset's structure:\n",
        "Our dataset would contains pairs of sentences.\n",
        "* Sentence 1 (Premise): Describes a person, profession, or role without using any gendered pronouns (words like \"he\", \"she\", \"her\", \"his\", \"herself\",...).\n",
        "\n",
        "* Sentence 2 (Hypothesis): Refers to the person from Sentence 1 using a gendered pronoun (he, she, or they).<br><br>\n",
        "\n",
        "**Example:** <br>\n",
        "Sentence 1: My **sister Shelly** is bery beautiful.<br>\n",
        "Sentence 2: **She** works as a model.<br><br>\n",
        "\n",
        "By using this structure, we aim check whether the gender mentioned in the second sentence can be directly and unambiguously deduced from the first sentence = **the sentence is not biased**, or whether it contains gender inferences (the gender in it is not directly related to the person the first sentence is talking about) = **the sentence is biased**.<Br><br>\n",
        "\n",
        "**Example not biased:**<br>\n",
        "Sentence 1: In the classroom corner, Dana keeps a binder titled “My Brother’s Stories.”<br>\n",
        "Sentence 2: Her descriptions of Avi’s jokes always make us laugh.<br><br>\n",
        "\n",
        "**Explanation:**<br>\n",
        "Sentence 1 refers to “Dana,” a name strongly associated with females. Thus, the pronoun usage (the word \"She\") is contextually inferable and not biased.\n",
        "<br><Br>\n",
        "\n",
        "**Example biased:**<br>\n",
        "Sentence 1: A person walked into the library holding a stack of books.<br>\n",
        "Sentence 2: He asked if there was a place to charge his laptop.\n",
        "\n",
        "**Explanation**:<br>\n",
        "Sentence 1 uses “a person,” which is entirely gender-neutral and does not provide any cue about the individual’s gender. However, Sentence 2 introduces “he” without justification from the first sentence — this makes it a biased inference based on gender assumption."
      ],
      "metadata": {
        "id": "16Rlv0b5lMOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Then, we used prompt engineering to create the dataset**\n",
        "We gave specific instructions to the generative model \"ChatGPT 4o\", in order to help it create our dataset.\n",
        "\n",
        "* At first, we wrote all the details about our project, our goals and all the things to know about our classification synthetic dataset (including examples of valid biased and not biased sentences).<br><br>\n",
        " Then, we asked the LLM to provide prompt instructuions to a generative model that will generate the dataset for us. <br>\n",
        "## **The prompt instructions it returned and all the other ones we wrote are in the bottom of this notebook:**<br><br>\n",
        "\n",
        "In the first prompt instructions it provided, it was written to genenared only 10 samples of pairs (so we could check its quality)."
      ],
      "metadata": {
        "id": "iwmfOJ33pUx1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It generated 10 **good examples**, so we thought it would also do a great at generating a large number of samples.\n",
        "So, asked it to create a csv file, containing 4000 examples of sentences like those it has generated.<br><br>\n",
        "\n",
        "However, it worked poorly and generated many similar (almost the same) sentences, such as:<br>\n",
        "\"Everyone expected the manager to lead, but it was a quiet father in the back who offered the most logical path forward.\"<br><Br>\n",
        "This sentence appeared 200 times (out of 4000 samples), each time with a diferent noun (here the word father).<br>\n",
        "\n",
        "In literature, it was written that **smaller missions work better than bigger ones**.<br> Therefore, we generated almost 4000 samples, **when each time, we asked ChatGPT 4o to only generate 30.** It did actually help, and this time, all the sentences were different from one another and well structured.<br><br>\n",
        "\n",
        "This way, we could check its samples one by one and make sure everything is well made and balanced.<Br> For instance, we could see that all 30 examples it generated all started with the person spoken about in the first sentence.<br>\n",
        "That way we could notice it that and instruct ChatGPT to generate more unique stractured sentences, like:<br><br>\n",
        "Sentence 1: \"Even during the blackout, the data analyst found a way to export the report.\"\n",
        "<br>Sentence 2: \"She finished it by candlelight.\"\n"
      ],
      "metadata": {
        "id": "VxnD9M6ZuAbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Labeling the dataset + Preprocessing Steps**\n",
        "\n",
        "# **@@@@@@@@@@@@@@@@@@@@**\n",
        "In order to label the sentences to biased/ not biased, we labeled the dataset all by ourselves, sample by sample.<br>\n",
        "At first, we asked ChatGPT 4o to label them according to our general instructions, and then we checked it by going through each sample, and making sure it is valid."
      ],
      "metadata": {
        "id": "NFI6YqJBQvQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### That way we created a unique, organized and accurate dataset, using synthetic data and a generative model\n",
        "\n",
        "**Prompts We Wrote Are In The Bottom of This Notebook**\n"
      ],
      "metadata": {
        "id": "cBU-zTpxypVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading our pairs dataset and learning statistics\n",
        "\n",
        "* First, we get an access to our drive, where the labeled dataset is in."
      ],
      "metadata": {
        "id": "xX3WkncRBUxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zafRnzDNCQKU",
        "outputId": "5f639289-97b2-42f4-cd26-593fe3965582"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using gpu"
      ],
      "metadata": {
        "id": "5_OrcgBsCCZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzBS-H-WCQ5f",
        "outputId": "54986482-8dc6-4e1d-c202-ac0e92688361"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dir_path = dir_path = '/content/drive/MyDrive/'\n",
        "os.listdir(dir_path)\n",
        "print(dir_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUFH5i3HENxG",
        "outputId": "f2d66aa5-258b-4946-f9e0-4b0a8e0991a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading our dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv(dir_path+ \"/labeled_dataset1.csv\")"
      ],
      "metadata": {
        "id": "UQWWZ2zoBxkw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will observe how maby samples are there in our final dataset after all preprocessing."
      ],
      "metadata": {
        "id": "wlx-v9EWCHrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the number of sentence pairs we have\n",
        "print(\"we have a total of \" ,len(df), \"pairs of sentences in the dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ_vFsI-Ixtm",
        "outputId": "273d2b96-f60e-47dd-c9ea-ce0c44478fa5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we have a total of  3421 pairs of sentences in the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JpJSvUuIcHOW",
        "outputId": "89d15f3a-c9c4-4424-d094-2fa790a5eb85"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Sentence1  \\\n",
              "0  My cousin opened a tiny repair shop near the t...   \n",
              "1  From the back of the classroom, the teacher wa...   \n",
              "2  Few knew that my grandma had once worked as a ...   \n",
              "3  The firefighter, soaked in sweat, emerged with...   \n",
              "4  There's a chef in our neighborhood who never r...   \n",
              "\n",
              "                                       Sentence2  bias_label  \n",
              "0      He's been fixing watches since childhood.         1.0  \n",
              "1                      Her patience was endless.         1.0  \n",
              "2  She never talked about her broadcasting days.         0.0  \n",
              "3                 His bravery stunned the crowd.         1.0  \n",
              "4                  People admire his creativity.         1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea37fabc-ced3-422a-b4b6-7b0e1db1d576\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence1</th>\n",
              "      <th>Sentence2</th>\n",
              "      <th>bias_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My cousin opened a tiny repair shop near the t...</td>\n",
              "      <td>He's been fixing watches since childhood.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From the back of the classroom, the teacher wa...</td>\n",
              "      <td>Her patience was endless.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Few knew that my grandma had once worked as a ...</td>\n",
              "      <td>She never talked about her broadcasting days.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The firefighter, soaked in sweat, emerged with...</td>\n",
              "      <td>His bravery stunned the crowd.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>There's a chef in our neighborhood who never r...</td>\n",
              "      <td>People admire his creativity.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea37fabc-ced3-422a-b4b6-7b0e1db1d576')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea37fabc-ced3-422a-b4b6-7b0e1db1d576 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea37fabc-ced3-422a-b4b6-7b0e1db1d576');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e6b60e18-44c7-4325-a80f-425a02b80a07\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6b60e18-44c7-4325-a80f-425a02b80a07')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e6b60e18-44c7-4325-a80f-425a02b80a07 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3421,\n  \"fields\": [\n    {\n      \"column\": \"Sentence1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3415,\n        \"samples\": [\n          \"Under a tent made from recycled banners, Grandpa Owen teaches wind physics to local kids.\",\n          \"Henry made a puppet stage out of cereal boxes for language practice.\",\n          \"The folk singer performed in six languages at the cultural festival.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3416,\n        \"samples\": [\n          \"The admiration his team received came as no surprise.\",\n          \"She believes good deeds deserve ink.\",\n          \"Her final song brought the whole crowd to its feet.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4998548925671588,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(print(df['bias_label'].value_counts()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nASlsku6b3l1",
        "outputId": "78d6061c-b462-47c6-cd99-97563ae6f78f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Sentence1', 'Sentence2', 'bias_label'], dtype='object')\n",
            "bias_label\n",
            "0.0    1760\n",
            "1.0    1659\n",
            "Name: count, dtype: int64\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Compute lengths\n",
        "df['len1'] = df['Sentence1'].apply(lambda x: len(str(x).split()))\n",
        "df['len2'] = df['Sentence2'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"Sentence 1 length:\")\n",
        "print(df['len1'].describe())\n",
        "print(\"\\nSentence 2 length:\")\n",
        "print(df['len2'].describe())\n",
        "\n",
        "# Plot histograms\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['len1'], bins=20, edgecolor='black')\n",
        "plt.title(\"Sentence 1 Length Distribution\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['len2'], bins=20, edgecolor='black')\n",
        "plt.title(\"Sentence 2 Length Distribution\")\n",
        "plt.xlabel(\"Number of Words\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "3YAriAl1_2q1",
        "outputId": "57907d4b-70ab-45ea-bb15-5f83828b7cc6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 length:\n",
            "count    3421.000000\n",
            "mean       11.852967\n",
            "std         3.118284\n",
            "min         5.000000\n",
            "25%        10.000000\n",
            "50%        11.000000\n",
            "75%        13.000000\n",
            "max        27.000000\n",
            "Name: len1, dtype: float64\n",
            "\n",
            "Sentence 2 length:\n",
            "count    3421.000000\n",
            "mean        7.168080\n",
            "std         2.127401\n",
            "min         1.000000\n",
            "25%         6.000000\n",
            "50%         7.000000\n",
            "75%         8.000000\n",
            "max        22.000000\n",
            "Name: len2, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the Classification Model**"
      ],
      "metadata": {
        "id": "Gh9Jr-Uvzf8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Approach\n",
        "\n",
        "In almost every field, from deep learning and machine learning to NLP, transfer learning through fine-tuning is a useful powerful technique to enhance model accuracy, efficiency, and overall performance.\n",
        "\n",
        "The core idea behind transfer learning is to leverage pre-trained models that have already been trained on large, diverse datasets—and adapt them to specific tasks. <Br><Br>By fine-tuning these models on our dataset, we can significantly reduce training time and computational costs while benefiting from the rich feature representations learned during the original training process.\n",
        "\n",
        "## In our project:\n",
        "In our project, we apply fine-tuning to pre-trained transformer models to detect gender bias in Natural Language Inference (NLI) tasks.<br> Specifically, we work with sentence pairs. Our goal is to classify whether the second sentence in each pair contains a justified or biased gender reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "vt1MGpSFzf-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Models We will Build And compare:\n",
        "* standard BERT architecture, with different freezing stradegies.\n",
        "* SBERT (Sentence-BERT) Classifier with logistic regression.\n",
        "* Generative Model Baseline (GPT-3.5 / GPT-4o)\n"
      ],
      "metadata": {
        "id": "7cWEX_aOHSie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine Tuning Standard Bert Model:**\n",
        "**BERT** was explicitly designed to support sentence-pair tasks such as Natural Language Inference (NLI) and Question Answering. Its input follows a special structure:<br><br>\n",
        "\n",
        "[CLS] **Sentence A** [SEP] **Sentence B** [SEP]<br>\n",
        "where:<br>\n",
        "[CLS]: A special classification token added at the beginning.<br>\n",
        "[SEP]: Separator token used to divide the two sentences<br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "U4vnwjg0IXFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwKvQa2cdCEo",
        "outputId": "02eedd2e-87c3-439f-8bad-8c8099f1105e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate --quiet\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import load_dataset, Dataset\n",
        "import evaluate\n"
      ],
      "metadata": {
        "id": "GIR6U1gNROu9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CONFIG ===\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "RUN_NAME = \"bert_bias_run1\"\n",
        "NUM_LABELS = 2\n",
        "NUM_EPOCHS = 8\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "LOGGING_STEPS = 10\n",
        "\n",
        "SAVE_DIR = f\"./results/{RUN_NAME}\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "KMpVHPokLA7_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "first, we rename the columns of our dataset to be: \"premise\" , \"hypothesis\",\"label\"."
      ],
      "metadata": {
        "id": "vdf27x26IXJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZlhx_SrSYDn",
        "outputId": "65deeb7e-4b83-4691-eccc-f918a46a6e9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Sentence1', 'Sentence2', 'bias_label', 'len1', 'len2'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns\n",
        "df = df.rename(columns={\n",
        "    \"Sentence1\": \"premise\",\n",
        "    \"Sentence2\": \"hypothesis\",\n",
        "    \"bias_label\": \"label\"  # replace with your actual label column name\n",
        "})\n",
        "\n",
        "# Check result\n",
        "print(\"new columns are: \", df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4MamHhxCrOn",
        "outputId": "830b44d7-7212-4eaa-d28b-b428ea277db7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new columns are:  Index(['premise', 'hypothesis', 'label', 'len1', 'len2'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### splitting to train and test:"
      ],
      "metadata": {
        "id": "8-8dJ23bUNKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "# Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: First split into train+val and test (85% train+val, 15% test)\n",
        "train_val_df, test_data = train_test_split(df, test_size=0.15, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "# Step 3: Split train+val into train and val (about 82% train, 18% val of the 85%)\n",
        "train_data, val_data = train_test_split(train_val_df, test_size=0.176, stratify=train_val_df[\"label\"], random_state=42)\n",
        "# 0.176 ≈ 15% / 85%\n",
        "\n",
        "# Convert to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(train_data)\n",
        "val_dataset = Dataset.from_pandas(val_data)\n",
        "test_dataset = Dataset.from_pandas(test_data)\n"
      ],
      "metadata": {
        "id": "DdFVL2JAPbfp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the tokenizer:"
      ],
      "metadata": {
        "id": "cmlaRineTC0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "VOeuwTYMSsUN"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization: Each pair is tokenized using the standard BERT tokenizer. It automatically:\n",
        "\n",
        "* Adds [CLS] at the beginning\n",
        "\n",
        "* Adds [SEP] between the two sentences and at the end<br>\n",
        "\n",
        "Generates attention masks and token type IDs"
      ],
      "metadata": {
        "id": "uoM8kdBfTFdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"premise\"], example[\"hypothesis\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"premise\", \"hypothesis\", \"__index_level_0__\"])\n",
        "val_dataset = val_dataset.remove_columns([\"premise\", \"hypothesis\", \"__index_level_0__\"])\n",
        "test_dataset = test_dataset.remove_columns([\"premise\", \"hypothesis\", \"__index_level_0__\"])\n",
        "\n",
        "\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "test_dataset.set_format(\"torch\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "d2282e4ec30e4354bd04253d62e40683",
            "86e9f5cda752488b92f90dea65e5cdf0",
            "51d5b2ca19ae41caa923b094566e4f28",
            "3cf617d3e02248e89ad4709da5d92557",
            "42a533cac8a84bb29d193eab9c76eefc",
            "2b05d3a1333949868a683b98bb0754fc",
            "989e756714324068b3c54c98e5a985b5",
            "9afe6936bb134123b3f0fff952522dd6",
            "60269392fce34141ab4fddad21edb5d5",
            "0dddf9b82c7f49dab8a9885519fcdecc",
            "53346b57def94619a84f510c7c7ba8e2",
            "fb38fd4e51ac42b5a2ac059ca37b29e9",
            "97a2389e06a644cab22c5a8339d1f8df",
            "8f112773afee46158ef291779ac16946",
            "912e1f837f00479185f3fd821d57ac42",
            "059caa1f7a1745998a61d6142f60a095",
            "f4475b8cd6824de09095371015cd8427",
            "06518f6c0f554375bbb1b34077ceeba8",
            "836d8d64ddf8489892d8a9bd02eefdd4",
            "9b9227f78fdf4fbcadf04ea15a723f0e",
            "768963a50a9242e195f8614303a8335f",
            "6d8c879c8469465fb5299f28c0af3415",
            "e289876a536a415586f1307d5ef01444",
            "a83bed1b090447e9afbdfeb0709da289",
            "763a3079d2e049709c9bcba5ec488890",
            "ab1a252ee5324c9dac7b9abe531dc898",
            "1130ce91df4940adbc025211cffb5def",
            "186d379aead647a1b7d3122e60f1c712",
            "283a19429c124ebbbc6738ad64ea235d",
            "4da3a96bef694d76966dbb8be489ee78",
            "9d16d95a44f540b186cb1dcebaa44c3f",
            "43664b0b57884410a0a746db3dc702c1",
            "6c4a79705aed4c899be3a897eea82807"
          ]
        },
        "id": "CmXcw_G0TRIZ",
        "outputId": "d2605d6f-a8b0-4a99-f919-91b32efca930"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2394 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2282e4ec30e4354bd04253d62e40683"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb38fd4e51ac42b5a2ac059ca37b29e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/513 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e289876a536a415586f1307d5ef01444"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading BERT with a classification head (2 classes)\n",
        "\n",
        "We use Hugging Face’s BertForSequenceClassification:<br>\n",
        "\n",
        "* Is is pre-trained on language modeling\n",
        "\n",
        "* Adds a classification head on top of the [CLS] token\n",
        "\n",
        "* Outputs logits for binary classification (bias vs. not bias)"
      ],
      "metadata": {
        "id": "sG7kupdyFBVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfDVdbr_Eukh",
        "outputId": "3fdae2ed-2897-468f-ffe9-b0dbceb2df0d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "precision = evaluate.load(\"precision\")\n",
        "recall = evaluate.load(\"recall\")\n",
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy.compute(predictions=preds, references=p.label_ids)[\"accuracy\"],\n",
        "        \"precision\": precision.compute(predictions=preds, references=p.label_ids, average=\"weighted\")[\"precision\"],\n",
        "        \"recall\": recall.compute(predictions=preds, references=p.label_ids, average=\"weighted\")[\"recall\"],\n",
        "        \"f1\": f1.compute(predictions=preds, references=p.label_ids, average=\"weighted\")[\"f1\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "330qp_SNNPnK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining training configuration"
      ],
      "metadata": {
        "id": "B_wEAYUbFdxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "def get_training_args(save_dir, batch_size=16, lr=2e-5):\n",
        "    return TrainingArguments(\n",
        "        output_dir=save_dir,\n",
        "        overwrite_output_dir=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=8,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f\"{save_dir}/logs\",\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"eval_f1\",\n",
        "        save_total_limit=1,\n",
        "        report_to=\"none\"\n",
        "    )"
      ],
      "metadata": {
        "id": "XhuoFXn-FeIH"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainer setup"
      ],
      "metadata": {
        "id": "T7amK5W0FlYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer_setup(model, save_dir):\n",
        "    return Trainer(\n",
        "        model=model,\n",
        "        args=get_training_args(save_dir),\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,  # Validation during training\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorWithPadding(tokenizer),\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )"
      ],
      "metadata": {
        "id": "BKFKX5SsFnR-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def training_func_and_results(trainer):\n",
        "    print(\"Training with epoch timing...\")\n",
        "    start_train = time.time()\n",
        "\n",
        "    trainer.train(resume_from_checkpoint=False)\n",
        "\n",
        "    end_train = time.time()\n",
        "    print(f\"Total training time: {(end_train - start_train)/60:.2f} minutes\\n\")\n",
        "\n",
        "    # Print epoch logs\n",
        "    print(\"Epoch-wise Evaluation Results:\")\n",
        "    for log in trainer.state.log_history:\n",
        "        if 'eval_loss' in log:\n",
        "            epoch = int(log['epoch'])\n",
        "            eval_loss = log.get('eval_loss')\n",
        "            f1 = log.get('eval_f1')\n",
        "            acc = log.get('eval_accuracy')\n",
        "            print(f\"Epoch {epoch}: Eval Loss={eval_loss:.4f}, F1={f1:.4f}, Accuracy={acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "SHLqELU5a9jA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freezing Layers\n",
        "Freezing a layer means not updating its weights while training the model.\n",
        "\n",
        "Why is it helpful?\n",
        "1. It can significantly reduce the training time (Instead of retraining the entire model, which can be computationally expensive, you only train the new layers added for your specific task)\n",
        "\n",
        "2. It helps in preventing overfitting. By not updating the weights of the frozen layers, you avoid tweaking features that are already well-established and generalize well across different tasks.\n",
        "\n",
        "Since our dataset of sentence pairs is very different from the data Bert was pretrained on (BooksCorpus (800M words) and English Wikipedia (2.5B words)), we are going to try and freeze different layers of the data and check what performs better:\n",
        "\n",
        "* First, we will freeze some of the front (first) layers, and train the last ones, in order to use general features learned by the pre-trained model, but learn more complex patterns and behaviors from the MRI data.\n",
        "* Then we will freeze more layers\n",
        "* Finally, we will freeze all layers, and train only the classification head."
      ],
      "metadata": {
        "id": "74svTO26hvml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4brbxMriuDW",
        "outputId": "6f265e89-4eae-46a2-f573-51a9f11f7980"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_train_eval_loss(trainer):\n",
        "    logs = trainer.state.log_history\n",
        "    train_loss = []\n",
        "    eval_loss = []\n",
        "    epochs = []\n",
        "\n",
        "    for entry in logs:\n",
        "        if \"loss\" in entry and \"epoch\" in entry:\n",
        "            train_loss.append(entry[\"loss\"])\n",
        "            epochs.append(entry[\"epoch\"])\n",
        "        if \"eval_loss\" in entry:\n",
        "            eval_loss.append(entry[\"eval_loss\"])\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs[:len(train_loss)], train_loss, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(epochs[:len(eval_loss)], eval_loss, label=\"Validation Loss\", marker='o')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training vs. Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VT9Y47JKnkqc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def reset_all_weights(model):\n",
        "    \"\"\"\n",
        "    Resets all weights in a Hugging Face BERT model, including the encoder and classification head.\n",
        "    Uses normal initialization with std=0.02 (default for BERT).\n",
        "    \"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, std=0.02)\n",
        "            if hasattr(module, 'padding_idx') and module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            nn.init.ones_(module.weight)\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "    print(\"✅ All BERT weights reset (encoder + classifier).\")\n"
      ],
      "metadata": {
        "id": "ne-c1zruk0ld"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving On To SBERT Model"
      ],
      "metadata": {
        "id": "a3lpDEegzgFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_sbert_layers(model, freeze_ratio=0.5, freeze_embeddings=False):\n",
        "    encoder = model.base_model  # works for RoBERTa, BERT, etc.\n",
        "\n",
        "    try:\n",
        "        layers = encoder.encoder.layer  # works for most transformer-based models\n",
        "    except AttributeError:\n",
        "        raise ValueError(\"Cannot access encoder layers — is this a supported SBERT model?\")\n",
        "\n",
        "    total_layers = len(layers)\n",
        "    num_to_freeze = int(total_layers * freeze_ratio)\n",
        "\n",
        "    # Freeze bottom `num_to_freeze` layers\n",
        "    for idx, layer in enumerate(layers):\n",
        "        if idx < num_to_freeze:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    if freeze_embeddings:\n",
        "        for param in encoder.embeddings.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    print(f\"Frozen {num_to_freeze}/{total_layers} encoder layers\")\n",
        "    if freeze_embeddings:\n",
        "        print(\"Embeddings are frozen\")\n"
      ],
      "metadata": {
        "id": "-cY92Z8pa-T9"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 - freezing 25% of the layers\n",
        "First, we are going to freeze about a quarter of the layers, which are \"conv1\", \"layer1\" and \"layer2\"\n",
        "\n"
      ],
      "metadata": {
        "id": "xm5Nwc1czgC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Use SBERT checkpoint (e.g., trained on NLI)\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "\n",
        "# Load as a Hugging Face model — note: it's RoBERTa architecture under the hood\n",
        "sbert_model_25 = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer_sbert_25 = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Move to CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sbert_model_25.to(device)\n",
        "\n",
        "freeze_sbert_layers(sbert_model_25, freeze_ratio=0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocOGOU0HY3mN",
        "outputId": "d368851b-8742-4114-863a-3d5b8edcc1e2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen 3/12 encoder layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_all_weights(sbert_model_25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeO4lpBVaEnX",
        "outputId": "a533028c-456d-4dcd-b19e-28f4c9afc853"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All BERT weights reset (encoder + classifier).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer1 = trainer_setup(sbert_model_25, \"./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert\")\n",
        "training_func_and_results(trainer1)\n",
        "# Evaluate on test set\n",
        "test_results1 = trainer1.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "S8a_ZdlzaPTJ",
        "outputId": "876a9cd1-f643-4555-b777-d23eed4b3aea"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with epoch timing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-4564a6e4764e>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='900' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 900/1200 13:37 < 04:33, 1.10 it/s, Epoch 6/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.423081</td>\n",
              "      <td>0.839844</td>\n",
              "      <td>0.861550</td>\n",
              "      <td>0.839844</td>\n",
              "      <td>0.836637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.301300</td>\n",
              "      <td>0.331257</td>\n",
              "      <td>0.880859</td>\n",
              "      <td>0.883146</td>\n",
              "      <td>0.880859</td>\n",
              "      <td>0.880504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>0.362449</td>\n",
              "      <td>0.908203</td>\n",
              "      <td>0.910669</td>\n",
              "      <td>0.908203</td>\n",
              "      <td>0.908183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.342385</td>\n",
              "      <td>0.912109</td>\n",
              "      <td>0.912715</td>\n",
              "      <td>0.912109</td>\n",
              "      <td>0.912131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.083100</td>\n",
              "      <td>0.408033</td>\n",
              "      <td>0.908203</td>\n",
              "      <td>0.911193</td>\n",
              "      <td>0.908203</td>\n",
              "      <td>0.908166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.030900</td>\n",
              "      <td>0.431291</td>\n",
              "      <td>0.910156</td>\n",
              "      <td>0.910203</td>\n",
              "      <td>0.910156</td>\n",
              "      <td>0.910166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 13.65 minutes\n",
            "\n",
            "Epoch-wise Evaluation Results:\n",
            "Epoch 1: Eval Loss=0.4231, F1=0.8366, Accuracy=0.8398\n",
            "Epoch 2: Eval Loss=0.3313, F1=0.8805, Accuracy=0.8809\n",
            "Epoch 3: Eval Loss=0.3624, F1=0.9082, Accuracy=0.9082\n",
            "Epoch 4: Eval Loss=0.3424, F1=0.9121, Accuracy=0.9121\n",
            "Epoch 5: Eval Loss=0.4080, F1=0.9082, Accuracy=0.9082\n",
            "Epoch 6: Eval Loss=0.4313, F1=0.9102, Accuracy=0.9102\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33/33 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 0.37003836035728455, 'eval_accuracy': 0.9064327485380117, 'eval_precision': 0.9071572312351426, 'eval_recall': 0.9064327485380117, 'eval_f1': 0.9064505272545056, 'eval_runtime': 10.5101, 'eval_samples_per_second': 48.81, 'eval_steps_per_second': 3.14, 'epoch': 6.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where to save the model\n",
        "SAVE_PATH1 = \"./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert\"\n",
        "\n",
        "# Save the model, tokenizer, and config\n",
        "trainer1.save_model(SAVE_PATH1)\n",
        "tokenizer_sbert_25.save_pretrained(SAVE_PATH1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsVNjpjFcSDv",
        "outputId": "cec11718-6a48-4f60-f34c-a094e04f335e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert/tokenizer_config.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert/special_tokens_map.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert/vocab.txt',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert/added_tokens.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df25 = pd.DataFrame([test_results1])  # test_results is from trainer.evaluate(test_dataset)\n",
        "results_df25.to_csv(\"./results/eval_results_25.csv\", index=False)"
      ],
      "metadata": {
        "id": "sRrImLPlbD0z"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model_25 = BertForSequenceClassification.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert\")\n",
        "tokenizer_sbert_25 = BertTokenizerFast.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh32nGdEcdmD",
        "outputId": "efd91209-c3cd-4469-c5b6-70832b2f7def"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type mpnet to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/saved_models/bert_finetuned_bias_25_sbert and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'MPNetTokenizer'. \n",
            "The class this function is called from is 'BertTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 - freezing 50% of the layers"
      ],
      "metadata": {
        "id": "hBu-S1HwVE4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load as a Hugging Face model — note: it's RoBERTa architecture under the hood\n",
        "sbert_model_50 = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer_sbert_50 = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Move to CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sbert_model_50.to(device)\n",
        "\n",
        "freeze_sbert_layers(sbert_model_50, freeze_ratio=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ReY1YkniwS_",
        "outputId": "b8597fd9-b414-4912-8fe9-e013c8006339"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen 6/12 encoder layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_all_weights(sbert_model_50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2oSQk33jAuu",
        "outputId": "3a0d4b80-20ab-471b-ecc8-4b7808a88e26"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All BERT weights reset (encoder + classifier).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer2 = trainer_setup(sbert_model_50, \"./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert\")\n",
        "training_func_and_results(trainer2)\n",
        "# Evaluate on test set\n",
        "test_results2 = trainer2.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "B8ryNbLujDlZ",
        "outputId": "d7e22292-08e1-4729-ec9b-dc24e236153d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-4564a6e4764e>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with epoch timing...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='997' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 997/1200 14:12 < 02:53, 1.17 it/s, Epoch 6.64/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.422300</td>\n",
              "      <td>0.486415</td>\n",
              "      <td>0.818359</td>\n",
              "      <td>0.848811</td>\n",
              "      <td>0.818359</td>\n",
              "      <td>0.813228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.364800</td>\n",
              "      <td>0.296067</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.893787</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.890222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.216200</td>\n",
              "      <td>0.302747</td>\n",
              "      <td>0.900391</td>\n",
              "      <td>0.900995</td>\n",
              "      <td>0.900391</td>\n",
              "      <td>0.900415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.210400</td>\n",
              "      <td>0.318766</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.920168</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.919873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.089100</td>\n",
              "      <td>0.358075</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925961</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>0.389284</td>\n",
              "      <td>0.923828</td>\n",
              "      <td>0.926883</td>\n",
              "      <td>0.923828</td>\n",
              "      <td>0.923798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1200/1200 17:17, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.422300</td>\n",
              "      <td>0.486415</td>\n",
              "      <td>0.818359</td>\n",
              "      <td>0.848811</td>\n",
              "      <td>0.818359</td>\n",
              "      <td>0.813228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.364800</td>\n",
              "      <td>0.296067</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.893787</td>\n",
              "      <td>0.890625</td>\n",
              "      <td>0.890222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.216200</td>\n",
              "      <td>0.302747</td>\n",
              "      <td>0.900391</td>\n",
              "      <td>0.900995</td>\n",
              "      <td>0.900391</td>\n",
              "      <td>0.900415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.210400</td>\n",
              "      <td>0.318766</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.920168</td>\n",
              "      <td>0.919922</td>\n",
              "      <td>0.919873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.089100</td>\n",
              "      <td>0.358075</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925961</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.106700</td>\n",
              "      <td>0.389284</td>\n",
              "      <td>0.923828</td>\n",
              "      <td>0.926883</td>\n",
              "      <td>0.923828</td>\n",
              "      <td>0.923798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.093100</td>\n",
              "      <td>0.406302</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925849</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>0.925759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.093500</td>\n",
              "      <td>0.402838</td>\n",
              "      <td>0.931641</td>\n",
              "      <td>0.931725</td>\n",
              "      <td>0.931641</td>\n",
              "      <td>0.931651</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 17.31 minutes\n",
            "\n",
            "Epoch-wise Evaluation Results:\n",
            "Epoch 1: Eval Loss=0.4864, F1=0.8132, Accuracy=0.8184\n",
            "Epoch 2: Eval Loss=0.2961, F1=0.8902, Accuracy=0.8906\n",
            "Epoch 3: Eval Loss=0.3027, F1=0.9004, Accuracy=0.9004\n",
            "Epoch 4: Eval Loss=0.3188, F1=0.9199, Accuracy=0.9199\n",
            "Epoch 5: Eval Loss=0.3581, F1=0.9257, Accuracy=0.9258\n",
            "Epoch 6: Eval Loss=0.3893, F1=0.9238, Accuracy=0.9238\n",
            "Epoch 7: Eval Loss=0.4063, F1=0.9258, Accuracy=0.9258\n",
            "Epoch 8: Eval Loss=0.4028, F1=0.9317, Accuracy=0.9316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33/33 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 0.4893089234828949, 'eval_accuracy': 0.9025341130604289, 'eval_precision': 0.9035487825566471, 'eval_recall': 0.9025341130604289, 'eval_f1': 0.9025474462870965, 'eval_runtime': 10.4793, 'eval_samples_per_second': 48.954, 'eval_steps_per_second': 3.149, 'epoch': 8.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df50 = pd.DataFrame([test_results2])  # test_results is from trainer.evaluate(test_dataset)\n",
        "results_df50.to_csv(\"./results/eval_results_50.csv\", index=False)"
      ],
      "metadata": {
        "id": "lWx3sNtXbOkP"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where to save the model\n",
        "SAVE_PATH2 = \"./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert\"\n",
        "\n",
        "# Save the model, tokenizer, and config\n",
        "trainer2.save_model(SAVE_PATH2)\n",
        "tokenizer_sbert_50.save_pretrained(SAVE_PATH2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLvncIyUjJvW",
        "outputId": "e18dcc7b-1e6a-4abb-884e-5ae9778518f2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert/tokenizer_config.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert/special_tokens_map.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert/vocab.txt',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert/added_tokens.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model_50 = BertForSequenceClassification.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert\")\n",
        "tokenizer_sbert_50 = BertTokenizerFast.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB7DDNhfjXTM",
        "outputId": "dbb78dd6-b92a-41f9-ef53-bd8ed9390841"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type mpnet to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/saved_models/bert_finetuned_bias_50_sbert and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'MPNetTokenizer'. \n",
            "The class this function is called from is 'BertTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 - freezing all layers, except Classifier Head"
      ],
      "metadata": {
        "id": "oU0RsX-0WDN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load as a Hugging Face model — note: it's RoBERTa architecture under the hood\n",
        "sbert_model_100 = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "tokenizer_sbert_100 = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Move to CUDA\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "sbert_model_100.to(device)\n",
        "\n",
        "freeze_sbert_layers(sbert_model_100, freeze_ratio=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFwL457Km3Np",
        "outputId": "c913537f-4e23-4be1-fcbf-1ee620ad12bf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen 12/12 encoder layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_all_weights(sbert_model_100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_o6su21m_4U",
        "outputId": "4704e2cb-1582-49ee-be1e-32525ea60118"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All BERT weights reset (encoder + classifier).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer3 = trainer_setup(sbert_model_100, \"./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert\")\n",
        "training_func_and_results(trainer3)\n",
        "# Evaluate on test set\n",
        "test_results3 = trainer3.evaluate(test_dataset)\n",
        "print(\"Test Results:\", test_results3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "dHKzw8vjnEeT",
        "outputId": "a245da49-fc52-4beb-b1d3-fbf2f8763420"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-4564a6e4764e>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  return Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with epoch timing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1200/1200 15:48, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.643900</td>\n",
              "      <td>0.644255</td>\n",
              "      <td>0.669922</td>\n",
              "      <td>0.728065</td>\n",
              "      <td>0.669922</td>\n",
              "      <td>0.642661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.613200</td>\n",
              "      <td>0.587948</td>\n",
              "      <td>0.738281</td>\n",
              "      <td>0.738467</td>\n",
              "      <td>0.738281</td>\n",
              "      <td>0.738329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539600</td>\n",
              "      <td>0.539548</td>\n",
              "      <td>0.722656</td>\n",
              "      <td>0.735664</td>\n",
              "      <td>0.722656</td>\n",
              "      <td>0.720272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.506900</td>\n",
              "      <td>0.489792</td>\n",
              "      <td>0.775391</td>\n",
              "      <td>0.775405</td>\n",
              "      <td>0.775391</td>\n",
              "      <td>0.775252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.463100</td>\n",
              "      <td>0.456526</td>\n",
              "      <td>0.800781</td>\n",
              "      <td>0.800781</td>\n",
              "      <td>0.800781</td>\n",
              "      <td>0.800781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.437133</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.805176</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.804735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.406600</td>\n",
              "      <td>0.422905</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.427600</td>\n",
              "      <td>0.418844</td>\n",
              "      <td>0.816406</td>\n",
              "      <td>0.816394</td>\n",
              "      <td>0.816406</td>\n",
              "      <td>0.816350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 15.82 minutes\n",
            "\n",
            "Epoch-wise Evaluation Results:\n",
            "Epoch 1: Eval Loss=0.6443, F1=0.6427, Accuracy=0.6699\n",
            "Epoch 2: Eval Loss=0.5879, F1=0.7383, Accuracy=0.7383\n",
            "Epoch 3: Eval Loss=0.5395, F1=0.7203, Accuracy=0.7227\n",
            "Epoch 4: Eval Loss=0.4898, F1=0.7753, Accuracy=0.7754\n",
            "Epoch 5: Eval Loss=0.4565, F1=0.8008, Accuracy=0.8008\n",
            "Epoch 6: Eval Loss=0.4371, F1=0.8047, Accuracy=0.8047\n",
            "Epoch 7: Eval Loss=0.4229, F1=0.8125, Accuracy=0.8125\n",
            "Epoch 8: Eval Loss=0.4188, F1=0.8164, Accuracy=0.8164\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33/33 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results: {'eval_loss': 0.42396214604377747, 'eval_accuracy': 0.7894736842105263, 'eval_precision': 0.7894432437368726, 'eval_recall': 0.7894736842105263, 'eval_f1': 0.7894464554569625, 'eval_runtime': 10.4821, 'eval_samples_per_second': 48.94, 'eval_steps_per_second': 3.148, 'epoch': 8.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df100 = pd.DataFrame([test_results3])  # test_results is from trainer.evaluate(test_dataset)\n",
        "results_df100.to_csv(\"./results/eval_results_100.csv\", index=False)"
      ],
      "metadata": {
        "id": "nMIGFNVWbVr0"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where to save the model\n",
        "SAVE_PATH3 = \"./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert\"\n",
        "\n",
        "# Save the model, tokenizer, and config\n",
        "trainer3.save_model(SAVE_PATH3)\n",
        "tokenizer_sbert_100.save_pretrained(SAVE_PATH3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76AmyA1rnNY4",
        "outputId": "83c26f32-a8af-426d-a985-944c2114b49d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert/tokenizer_config.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert/special_tokens_map.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert/vocab.txt',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert/added_tokens.json',\n",
              " './drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model_100 = BertForSequenceClassification.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert\")\n",
        "tokenizer_sbert_100 = BertTokenizerFast.from_pretrained(\"./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xSzge8mnSkF",
        "outputId": "b80c8a26-f75d-4572-822f-0ce903df5b7e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type mpnet to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./drive/MyDrive/saved_models/bert_finetuned_bias_100_sbert and are newly initialized: ['bert.embeddings.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'MPNetTokenizer'. \n",
            "The class this function is called from is 'BertTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT 3.5 Baseline Classifier Model"
      ],
      "metadata": {
        "id": "QjnyOEat0SXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a copy of our existing dataset (with the columns: \"premise\", \"hypothesis\", \"bias_label\")"
      ],
      "metadata": {
        "id": "VhxcB0DE1N7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt3 = pd.read_csv(dir_path+ \"/labeled_dataset1.csv\")"
      ],
      "metadata": {
        "id": "zaGSC3uS0ZqH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt3 = df_gpt3.dropna()"
      ],
      "metadata": {
        "id": "OB4mN4sHE4OI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_gpt3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLM2Xlo8IIZj",
        "outputId": "f9367ce2-59bc-4d42-b993-008eb2150540"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3419"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLCKGB2zBdTi",
        "outputId": "d062b867-0476-4d41-cc0e-b56b53a3c5f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.82.1\n",
            "    Uninstalling openai-1.82.1:\n",
            "      Successfully uninstalled openai-1.82.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # You can use `os.getenv(\"OPENAI_API_KEY\")` for safety\n",
        "\n",
        "instruction = \"\"\"\n",
        "You will be given sentence pairs.\n",
        "\n",
        "Each pair includes:\n",
        "Sentence 1: a neutral description of a person, profession, or role.\n",
        "Sentence 2: a follow-up sentence that may refer to the person using a gendered pronoun (like he/she/his/her).\n",
        "\n",
        "Your task: Classify each pair.\n",
        "Respond with \"0\" if the gendered reference is logically supported by the first sentence (not biased).\n",
        "Respond with \"1\" if the gendered reference is a gender-based assumption not clearly supported by the first sentence (biased).\n",
        "\n",
        "Return only a comma-separated list of 30 numbers (0 or 1), no extra text.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "_uh1NNrQ0EFb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_batch(sent1_list, sent2_list):\n",
        "    return \"\\n\\n\".join([\n",
        "        f\"Sentence 1: {s1}\\nSentence 2: {s2}\"\n",
        "        for s1, s2 in zip(sent1_list, sent2_list)\n",
        "    ])"
      ],
      "metadata": {
        "id": "hu3S7Otx-3ay"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def classify_batch_gpt_add_column(df, model, batch_size=30):\n",
        "    \"\"\"\n",
        "    Classifies sentence pairs using GPT and adds the predictions as a new column to the DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df (pd.DataFrame): Must include 'premise' and 'hypothesis' columns.\n",
        "    - batch_size (int): Number of sentence pairs per batch.\n",
        "    - model (str): GPT model name (e.g., \"gpt-3.5-turbo\").\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Original DataFrame with an added 'gpt_pred' column.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i in range(0, len(df), batch_size):\n",
        "        batch = df.iloc[i:i+batch_size]\n",
        "        prompt = instruction + \"\\n\\n\" + format_batch(batch['Sentence1'], batch['Sentence2'])\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            output = response['choices'][0]['message']['content'].strip()\n",
        "            preds = [int(x) for x in output.split(\",\") if x.strip().isdigit()]\n",
        "            # Fill in missing predictions if needed\n",
        "            while len(preds) < len(batch):\n",
        "                preds.append(random.choice([0, 1]))\n",
        "\n",
        "            results.extend(preds[:len(batch)])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error at batch {i}-{i+batch_size}: {e}\")\n",
        "            results.extend([-1] * len(batch))  # Mark failed predictions\n",
        "\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Add new column\n",
        "    df = df.copy()\n",
        "    df[\"gpt_pred\"] = results\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "WfL6nVkK0IKh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate_gpt_predictions(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates GPT predictions using standard classification metrics.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (List[int]): The ground truth labels (0 or 1).\n",
        "    - y_pred (List[int]): The predicted labels from GPT (0 or 1).\n",
        "\n",
        "    Returns:\n",
        "    - dict: Dictionary of evaluation metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    # Filter out invalid predictions if any (-1)\n",
        "    valid_indices = [i for i, pred in enumerate(y_pred) if pred in [0, 1]]\n",
        "    y_true_filtered = [y_true[i] for i in valid_indices]\n",
        "    y_pred_filtered = [y_pred[i] for i in valid_indices]\n",
        "\n",
        "    # Compute metrics\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_true_filtered, y_pred_filtered),\n",
        "        \"F1 Score\": f1_score(y_true_filtered, y_pred_filtered),\n",
        "        \"Precision\": precision_score(y_true_filtered, y_pred_filtered),\n",
        "        \"Recall\": recall_score(y_true_filtered, y_pred_filtered),\n",
        "        \"Valid Predictions\": len(y_pred_filtered),\n",
        "        \"Total Predictions\": len(y_pred)\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "-nASkwi28_qa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt3_and_a_half = classify_batch_gpt_add_column(df_gpt3, \"gpt-3.5-turbo\")\n",
        "\n",
        "# Save predictions\n",
        "output_path = os.path.join(dir_path, \"gpt_predictions.csv\")\n",
        "df_gpt3_and_a_half.to_csv(output_path, index=False)\n"
      ],
      "metadata": {
        "id": "242kn1gR_xnW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate (optional)\n",
        "metrics = evaluate_gpt_predictions(\n",
        "    df_gpt3_and_a_half[\"bias_label\"].tolist(),\n",
        "    df_gpt3_and_a_half[\"gpt_pred\"].tolist()\n",
        ")\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefwcL1aFAPk",
        "outputId": "9379dcde-4691-45b3-d7d4-f0e7012097d2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.6077800526469728, 'F1 Score': 0.5621939275220372, 'Precision': 0.6132478632478633, 'Recall': 0.5189873417721519, 'Valid Predictions': 3419, 'Total Predictions': 3419}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NDu1wb2qb11U",
        "outputId": "e07f3b1f-8a18-4a7f-85ff-91114c0d8be3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_66699cb4-4003-4f6f-b0c8-20e0ca3f36b5\", \"gpt_predictions.csv\", 446639)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT 4o Baseline Classifier Model"
      ],
      "metadata": {
        "id": "RHIHwKI4Rl-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt4o = pd.read_csv(dir_path+ \"/labeled_dataset1.csv\")\n",
        "df_gpt4o = df_gpt4o.dropna()"
      ],
      "metadata": {
        "id": "tVTYKJz0FXfL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gpt4o = classify_batch_gpt_add_column(df_gpt4o, \"gpt-4o\")\n",
        "\n",
        "# Save predictions\n",
        "output_path = os.path.join(dir_path, \"gpt_predictions2.csv\")\n",
        "df_gpt4o.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "g7jP4MP6FW6M"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rU61VXizLZqu",
        "outputId": "69ed10ed-a962-44ba-92a2-79831ddc546e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_21797334-dce5-4b5c-a77b-5edad33529cc\", \"gpt_predictions2.csv\", 446639)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate (optional)\n",
        "metrics = evaluate_gpt_predictions(\n",
        "    df_gpt4o[\"bias_label\"].tolist(),\n",
        "    df_gpt4o[\"gpt_pred\"].tolist()\n",
        ")\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67H5XSzyGnPc",
        "outputId": "638cff5b-1bdc-45c1-cd6a-85c83f9c283b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.6858730622989178, 'F1 Score': 0.5370689655172414, 'Precision': 0.9425113464447806, 'Recall': 0.3755274261603376, 'Valid Predictions': 3419, 'Total Predictions': 3419}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "q8yL0HLlzgHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prompts We wrote to create the classification dataset:**<br>\n",
        "#1: Beginning Prompt: (generating 10 pairs)\n",
        "You are a dataset generator for a contextual gender bias classification task using natural language inference (NLI).\n",
        "\n",
        "Each data sample consists of:\n",
        "\n",
        "Sentence 1 (premise): introduces a person or role.\n",
        "\n",
        "Sentence 2 (hypothesis): refers to that person using a gendered pronoun (he/she/they).\n",
        "\n",
        "Your task is to generate diverse sentence pairs across a wide variety of real-life categories. Each pair can be:\n",
        "\n",
        "Not biased: gender is explicitly inferable (e.g., \"My mother is a chef.\" → \"She works long hours.\")\n",
        "\n",
        "Biased: gender is assumed without being stated (e.g., \"The chef works long hours.\" → \"She often skips dinner.\")\n",
        "\n",
        "🔹 Categories to choose from (rotate between them):\n",
        "\n",
        "Occupations: nurse, CEO, engineer, janitor, journalist, developer, etc.\n",
        "\n",
        "Family Roles: sister, cousin, father, parent, child, etc.\n",
        "\n",
        "Education Roles: teacher, principal, tutor, coach, etc.\n",
        "\n",
        "Medical: doctor, nurse, therapist, etc.\n",
        "\n",
        "Leadership: judge, president, director, etc.\n",
        "\n",
        "Manual/Blue Collar Jobs: mechanic, driver, electrician, etc.\n",
        "\n",
        "Service Jobs: waiter, receptionist, cleaner, chef, etc.\n",
        "\n",
        "Sports: athlete, coach, referee, etc.\n",
        "\n",
        "Military/Law: soldier, pilot, police officer, etc.\n",
        "\n",
        "Entertainment: actor, dancer, musician, influencer, etc.\n",
        "\n",
        "Technology: developer, system admin, AI researcher\n",
        "\n",
        "Politics: senator, mayor, ambassador, diplomat\n",
        "\n",
        "🔹 Output Requirements:\n",
        "\n",
        "**Generate 10 sentence pairs per call.**\n",
        "\n",
        "Vary vocabulary and syntax: include simple, compound, and complex structures.\n",
        "\n",
        "Use both male, female, and neutral pronouns (he/she/they).\n",
        "\n",
        "Alternate between biased and non-biased examples (50/50 split).<br><br>\n",
        "\n",
        "✅ Example Outputs<br><br>\n",
        "{<br>\n",
        "  \"category\": \"occupation\",<br>\n",
        "  \"premise\": \"The nurse organized the patients' records carefully.\",<br>\n",
        "  \"hypothesis\": \"She made sure everyone was seen on time.\",<br>\n",
        "}<br><br>\n",
        "{<br>\n",
        "  \"category\": \"family\",<br>\n",
        "  \"premise\": \"My brother is a police officer.\",<br>\n",
        "  \"hypothesis\": \"He works night shifts every weekend.\",<br>\n",
        "}<br><br>\n",
        "\n",
        "\n",
        "#2: second prompt\n",
        "### this time:\n",
        "* Adding the requirement for differences between the syntactic structures of sentences, and sentence openings.\n",
        "* Asking for a balance of pronouns\n",
        "* Asking for realistic and natural language in the sentences\n",
        "----------------------------------------------\n",
        "\n",
        "You are a data generator for a contextual reasoning dataset focused on gender pronoun inference.\n",
        "\n",
        "Your task is to generate 3,000 high-quality sentence pairs, where each pair includes:\n",
        "\n",
        "Sentence 1 (Premise): Describes a person, profession, or role without using any gendered pronouns.\n",
        "\n",
        "Sentence 2 (Hypothesis): Refers to the person from Sentence 1 using a gendered pronoun (he, she, or they).\n",
        "\n",
        "These will be used in a Natural Language Inference (NLI) task to determine if the pronoun is inferable or biased.\n",
        "\n",
        "each one of the sentences will be different from one another, start in different words, and refer to somebody else. Not all of the second sentences(Hypothesis) will start with a gendered word (he, she,...), but only some of them. Use diverse gender words, like he, she, his, her, him,...\n",
        "\n",
        "In order to generate completely different sentences, please use some sentences from different sources on the internet.\n",
        "\n",
        "🔹 Generation Instructions:\n",
        "1. Diversity of Content:\n",
        "Rotate and mix examples from the following categories:\n",
        "\n",
        "Occupations (e.g., doctor, janitor, firefighter, CEO)\n",
        "\n",
        "Education (e.g., tutor, principal, student)\n",
        "\n",
        "Technology (e.g., developer, AI expert)\n",
        "\n",
        "Service roles (e.g., cleaner, waiter)\n",
        "\n",
        "Leadership (e.g., manager, judge, captain)\n",
        "\n",
        "Family/Relatives (e.g., sister, uncle, cousin, parent)\n",
        "\n",
        "Sports (e.g., athlete, coach, referee)\n",
        "\n",
        "Entertainment (e.g., actor, musician)\n",
        "\n",
        "Law & Military (e.g., police officer, pilot)\n",
        "\n",
        "Medical (e.g., surgeon, therapist)\n",
        "\n",
        "Politics (e.g., mayor, senator)\n",
        "\n",
        "2. Vary Sentence Structure and Style:\n",
        "Use a mix of formal and informal tones.\n",
        "\n",
        "Use diverse sentence structures: statements, compound/complex sentences, dialogue-style, descriptive, etc.\n",
        "\n",
        "Vary sentence openings:\n",
        "\n",
        "Not every sentence should begin with “A…” or “The…”.\n",
        "\n",
        "Use personal and relational contexts (e.g., “My cousin…”, “Our principal…”, “That musician…”).\n",
        "\n",
        "Use named characters occasionally (e.g., “Jordan is a firefighter…”).\n",
        "\n",
        "Use realistic and natural language, as if the sentences appeared in news articles, conversations, or reports.\n",
        "\n",
        "3. Balance of Pronouns:\n",
        "Use a balanced mix of:\n",
        "\n",
        "he\n",
        "\n",
        "she\n",
        "\n",
        "they (only when it refers to a group or ambiguous context — do not use “they” as a singular pronoun for one clearly described person).\n",
        "\n",
        "4. Avoid Repetition:\n",
        "Ensure each sentence pair is unique in wording and structure.\n",
        "\n",
        "Do not repeat openings like “The [role]…” in the majority of examples.\n",
        "\n",
        "Sentence 1 and Sentence 2 must be logically related but not identical in phrasing.\n",
        "\n",
        "🔹 Output Format:\n",
        "Each pair should be structured like this:\n",
        "\n",
        "Examples:\n",
        "\n",
        "Sentence 1: My cousin just landed a job as a data scientist.\n",
        "Sentence 2: She enjoys analyzing trends late into the night.\n",
        "\n",
        "Sentence 1: The therapist scheduled three new sessions for the week.\n",
        "Sentence 2: He believes consistency is key to progress.\n",
        "\n",
        "Sentence 1: During the flood rescue, Jordan coordinated all the first responders.\n",
        "Sentence 2: He were praised for his leadership under pressure.\n",
        "\n",
        "🔹 Total Required:\n",
        "Please generate exactly 3,000 sentence pairs, following the above constraints and stylistic guidance. also for each sentence give its category (Occupations, Education, Technology,.....)<br><Br><br>\n",
        "\n",
        "\n",
        "#3: Small prompts, like: <br>\n",
        "* now start from the beginning: generate 100 sentences with different structures (some start with the person spoken about, and some not), different gender words in the \"sentence 2\" sentences (he,she, he's, her's, her, his, him,...) and many occupations, and family terms (such as cousin, sister, brother, father, sibling, grandma, ...).\n",
        "\n",
        "(this was the first reduction of the amount of sentences we required it to generate)\n",
        "\n",
        "* please write 30 sentences (not in csv)\n",
        "\n",
        "(the 100 sentences generation did not work, so we moved dowm to 30)\n",
        "\n",
        "* continue generating sentences 101-130, but remember to start a part of them in the person spoken about, but others with other beginnings\n",
        "\n",
        "(making sure there is diversity)\n",
        "\n",
        "*  remember that a profession, a family relative, or some other person is referred/mentioned only in the first sentence, and the gender term is mentioned only in the second one\n",
        "\n",
        "\n",
        "(when it generated sentences without a person reference in the first sentence, like: <br>\n",
        "Sentence 1: The courtroom walls were covered in sketches from youth art programs.\n",
        "Sentence 2: The judge said his court should include all voices.\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "3xYoTZTFzgMa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xr3xeWzJBRy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --quiet\n",
        "import os\n",
        "os._exit(00)  # Restart the runtime cleanly after downgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vREo4Wqcljf",
        "outputId": "95888655-1752-4613-8584-aa97dd109a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/18.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/18.3 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/18.3 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m13.3/18.3 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m18.2/18.3 MB\u001b[0m \u001b[31m151.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m18.2/18.3 MB\u001b[0m \u001b[31m151.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hm-PMzDDIqbb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}